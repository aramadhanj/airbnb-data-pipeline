[2023-07-20 07:00:53,914] {processor.py:163} INFO - Started process (PID=62) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:00:53,932] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:00:53,934] {logging_mixin.py:109} INFO - [2023-07-20 07:00:53,934] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:00:58,261] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:01:05,573] {logging_mixin.py:109} INFO - [2023-07-20 07:01:05,572] {manager.py:496} INFO - Created Permission View: can edit on DAG:data_ingest
[2023-07-20 07:01:05,589] {logging_mixin.py:109} INFO - [2023-07-20 07:01:05,589] {manager.py:496} INFO - Created Permission View: can read on DAG:data_ingest
[2023-07-20 07:01:05,590] {logging_mixin.py:109} INFO - [2023-07-20 07:01:05,589] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:01:05,602] {logging_mixin.py:109} INFO - [2023-07-20 07:01:05,601] {dag.py:2415} INFO - Creating ORM DAG for data_ingest
[2023-07-20 07:01:05,621] {logging_mixin.py:109} INFO - [2023-07-20 07:01:05,620] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:01:05,649] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 11.762 seconds
[2023-07-20 07:01:36,610] {processor.py:163} INFO - Started process (PID=99) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:01:36,612] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:01:36,613] {logging_mixin.py:109} INFO - [2023-07-20 07:01:36,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:01:37,400] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:01:37,411] {logging_mixin.py:109} INFO - [2023-07-20 07:01:37,411] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:01:37,427] {logging_mixin.py:109} INFO - [2023-07-20 07:01:37,427] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:01:37,439] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.833 seconds
[2023-07-20 07:02:07,781] {processor.py:163} INFO - Started process (PID=125) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:02:07,782] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:02:07,783] {logging_mixin.py:109} INFO - [2023-07-20 07:02:07,783] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:02:08,461] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:02:08,471] {logging_mixin.py:109} INFO - [2023-07-20 07:02:08,471] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:02:08,488] {logging_mixin.py:109} INFO - [2023-07-20 07:02:08,488] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:02:08,498] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.722 seconds
[2023-07-20 07:02:38,975] {processor.py:163} INFO - Started process (PID=160) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:02:38,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:02:38,979] {logging_mixin.py:109} INFO - [2023-07-20 07:02:38,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:02:39,654] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:02:39,664] {logging_mixin.py:109} INFO - [2023-07-20 07:02:39,664] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:02:39,680] {logging_mixin.py:109} INFO - [2023-07-20 07:02:39,680] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:02:39,690] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.720 seconds
[2023-07-20 07:03:10,170] {processor.py:163} INFO - Started process (PID=187) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:03:10,172] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:03:10,173] {logging_mixin.py:109} INFO - [2023-07-20 07:03:10,173] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:03:10,833] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:03:10,843] {logging_mixin.py:109} INFO - [2023-07-20 07:03:10,843] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:03:10,859] {logging_mixin.py:109} INFO - [2023-07-20 07:03:10,859] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:03:10,869] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.703 seconds
[2023-07-20 07:03:41,356] {processor.py:163} INFO - Started process (PID=213) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:03:41,360] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:03:41,361] {logging_mixin.py:109} INFO - [2023-07-20 07:03:41,361] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:03:42,233] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:03:42,245] {logging_mixin.py:109} INFO - [2023-07-20 07:03:42,244] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:03:42,262] {logging_mixin.py:109} INFO - [2023-07-20 07:03:42,262] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:03:42,273] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.921 seconds
[2023-07-20 07:04:12,547] {processor.py:163} INFO - Started process (PID=248) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:12,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:04:12,549] {logging_mixin.py:109} INFO - [2023-07-20 07:04:12,548] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:13,183] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:13,193] {logging_mixin.py:109} INFO - [2023-07-20 07:04:13,193] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:04:13,209] {logging_mixin.py:109} INFO - [2023-07-20 07:04:13,209] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:04:13,219] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.677 seconds
[2023-07-20 07:04:43,744] {processor.py:163} INFO - Started process (PID=274) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:43,747] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:04:43,748] {logging_mixin.py:109} INFO - [2023-07-20 07:04:43,748] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:44,491] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:44,502] {logging_mixin.py:109} INFO - [2023-07-20 07:04:44,502] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:04:44,518] {logging_mixin.py:109} INFO - [2023-07-20 07:04:44,518] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00
[2023-07-20 07:04:44,529] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.790 seconds
[2023-07-20 07:04:55,850] {processor.py:163} INFO - Started process (PID=290) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:55,851] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:04:55,852] {logging_mixin.py:109} INFO - [2023-07-20 07:04:55,852] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:56,483] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:04:56,516] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 4, 51, 429778, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 4, 56, 501746, tzinfo=Timezone('UTC')), 'duration': 5}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:04:56,531] {logging_mixin.py:109} INFO - [2023-07-20 07:04:56,531] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:04:56,547] {logging_mixin.py:109} INFO - [2023-07-20 07:04:56,547] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:04:56,556] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.711 seconds
[2023-07-20 07:05:05,946] {processor.py:163} INFO - Started process (PID=305) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:05,947] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:05:05,948] {logging_mixin.py:109} INFO - [2023-07-20 07:05:05,948] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:06,627] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:06,669] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 4, 51, 429778, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 5, 6, 647239, tzinfo=Timezone('UTC')), 'duration': 15}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:05:06,692] {logging_mixin.py:109} INFO - [2023-07-20 07:05:06,692] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:05:06,714] {logging_mixin.py:109} INFO - [2023-07-20 07:05:06,714] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:05:06,728] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.790 seconds
[2023-07-20 07:05:16,043] {processor.py:163} INFO - Started process (PID=320) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:16,045] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:05:16,046] {logging_mixin.py:109} INFO - [2023-07-20 07:05:16,046] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:16,724] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:16,755] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 4, 51, 429778, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 5, 16, 742632, tzinfo=Timezone('UTC')), 'duration': 25}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:05:16,771] {logging_mixin.py:109} INFO - [2023-07-20 07:05:16,770] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:05:16,788] {logging_mixin.py:109} INFO - [2023-07-20 07:05:16,788] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:05:16,799] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.762 seconds
[2023-07-20 07:05:26,145] {processor.py:163} INFO - Started process (PID=335) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:26,147] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:05:26,148] {logging_mixin.py:109} INFO - [2023-07-20 07:05:26,148] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:27,062] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:27,095] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 4, 51, 429778, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 5, 27, 80308, tzinfo=Timezone('UTC')), 'duration': 35}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:05:27,112] {logging_mixin.py:109} INFO - [2023-07-20 07:05:27,112] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:05:27,129] {logging_mixin.py:109} INFO - [2023-07-20 07:05:27,129] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:05:27,140] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.004 seconds
[2023-07-20 07:05:57,335] {processor.py:163} INFO - Started process (PID=361) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:57,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:05:57,337] {logging_mixin.py:109} INFO - [2023-07-20 07:05:57,337] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:58,003] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:05:58,014] {logging_mixin.py:109} INFO - [2023-07-20 07:05:58,014] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:05:58,031] {logging_mixin.py:109} INFO - [2023-07-20 07:05:58,031] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:05:58,042] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.712 seconds
[2023-07-20 07:06:16,461] {processor.py:163} INFO - Started process (PID=386) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:16,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:06:16,466] {logging_mixin.py:109} INFO - [2023-07-20 07:06:16,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:17,148] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:17,184] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 6, 17, 169251, tzinfo=Timezone('UTC')), 'duration': 4}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:06:17,203] {logging_mixin.py:109} INFO - [2023-07-20 07:06:17,202] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:06:17,226] {logging_mixin.py:109} INFO - [2023-07-20 07:06:17,226] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:06:17,240] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.785 seconds
[2023-07-20 07:06:26,550] {processor.py:163} INFO - Started process (PID=392) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:26,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:06:26,553] {logging_mixin.py:109} INFO - [2023-07-20 07:06:26,552] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:27,258] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:27,290] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 6, 27, 275686, tzinfo=Timezone('UTC')), 'duration': 15}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:06:27,308] {logging_mixin.py:109} INFO - [2023-07-20 07:06:27,307] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:06:27,325] {logging_mixin.py:109} INFO - [2023-07-20 07:06:27,324] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:06:27,335] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.793 seconds
[2023-07-20 07:06:36,645] {processor.py:163} INFO - Started process (PID=407) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:36,647] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:06:36,648] {logging_mixin.py:109} INFO - [2023-07-20 07:06:36,648] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:37,391] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:37,444] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 6, 37, 419711, tzinfo=Timezone('UTC')), 'duration': 25}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:06:37,473] {logging_mixin.py:109} INFO - [2023-07-20 07:06:37,472] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:06:37,506] {logging_mixin.py:109} INFO - [2023-07-20 07:06:37,506] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:06:37,521] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.883 seconds
[2023-07-20 07:06:46,737] {processor.py:163} INFO - Started process (PID=422) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:46,739] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:06:46,740] {logging_mixin.py:109} INFO - [2023-07-20 07:06:46,740] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:47,434] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:47,476] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 6, 47, 459631, tzinfo=Timezone('UTC')), 'duration': 35}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:06:47,493] {logging_mixin.py:109} INFO - [2023-07-20 07:06:47,492] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:06:47,509] {logging_mixin.py:109} INFO - [2023-07-20 07:06:47,509] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:06:47,521] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.791 seconds
[2023-07-20 07:06:56,817] {processor.py:163} INFO - Started process (PID=437) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:56,819] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:06:56,820] {logging_mixin.py:109} INFO - [2023-07-20 07:06:56,820] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:57,477] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:06:57,512] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 6, 57, 496559, tzinfo=Timezone('UTC')), 'duration': 45}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:06:57,530] {logging_mixin.py:109} INFO - [2023-07-20 07:06:57,530] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:06:57,544] {logging_mixin.py:109} INFO - [2023-07-20 07:06:57,544] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:06:57,555] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.743 seconds
[2023-07-20 07:07:06,906] {processor.py:163} INFO - Started process (PID=443) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:06,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:07:06,909] {logging_mixin.py:109} INFO - [2023-07-20 07:07:06,909] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:07,723] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:07,765] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 7, 7, 749713, tzinfo=Timezone('UTC')), 'duration': 55}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:07:07,785] {logging_mixin.py:109} INFO - [2023-07-20 07:07:07,785] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:07:07,800] {logging_mixin.py:109} INFO - [2023-07-20 07:07:07,800] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:07:07,810] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.911 seconds
[2023-07-20 07:07:17,059] {processor.py:163} INFO - Started process (PID=459) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:17,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:07:17,068] {logging_mixin.py:109} INFO - [2023-07-20 07:07:17,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:19,164] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:19,247] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 7, 19, 214213, tzinfo=Timezone('UTC')), 'duration': 66}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:07:19,291] {logging_mixin.py:109} INFO - [2023-07-20 07:07:19,290] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:07:19,319] {logging_mixin.py:109} INFO - [2023-07-20 07:07:19,319] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:07:19,338] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 2.298 seconds
[2023-07-20 07:07:27,234] {processor.py:163} INFO - Started process (PID=474) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:27,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:07:27,239] {logging_mixin.py:109} INFO - [2023-07-20 07:07:27,238] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:28,615] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:28,677] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 7, 28, 651605, tzinfo=Timezone('UTC')), 'duration': 76}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:07:28,717] {logging_mixin.py:109} INFO - [2023-07-20 07:07:28,716] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:07:28,748] {logging_mixin.py:109} INFO - [2023-07-20 07:07:28,748] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:07:28,768] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.543 seconds
[2023-07-20 07:07:37,446] {processor.py:163} INFO - Started process (PID=487) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:37,450] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:07:37,454] {logging_mixin.py:109} INFO - [2023-07-20 07:07:37,453] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:40,434] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:40,549] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 7, 40, 487016, tzinfo=Timezone('UTC')), 'duration': 88}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:07:40,632] {logging_mixin.py:109} INFO - [2023-07-20 07:07:40,630] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:07:40,716] {logging_mixin.py:109} INFO - [2023-07-20 07:07:40,716] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:07:40,784] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 3.358 seconds
[2023-07-20 07:07:47,781] {processor.py:163} INFO - Started process (PID=495) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:47,785] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:07:47,787] {logging_mixin.py:109} INFO - [2023-07-20 07:07:47,787] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:49,206] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:49,272] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 7, 49, 242998, tzinfo=Timezone('UTC')), 'duration': 97}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:07:49,307] {logging_mixin.py:109} INFO - [2023-07-20 07:07:49,306] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:07:49,334] {logging_mixin.py:109} INFO - [2023-07-20 07:07:49,333] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:07:49,351] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.586 seconds
[2023-07-20 07:07:57,964] {processor.py:163} INFO - Started process (PID=510) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:57,968] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:07:57,970] {logging_mixin.py:109} INFO - [2023-07-20 07:07:57,969] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:58,854] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:07:58,891] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 7, 58, 874589, tzinfo=Timezone('UTC')), 'duration': 106}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:07:58,915] {logging_mixin.py:109} INFO - [2023-07-20 07:07:58,915] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:07:58,933] {logging_mixin.py:109} INFO - [2023-07-20 07:07:58,933] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:07:58,947] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.994 seconds
[2023-07-20 07:08:08,018] {processor.py:163} INFO - Started process (PID=516) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:08,020] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:08:08,021] {logging_mixin.py:109} INFO - [2023-07-20 07:08:08,020] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:08,918] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:08,960] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 8, 8, 945621, tzinfo=Timezone('UTC')), 'duration': 116}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:08:08,982] {logging_mixin.py:109} INFO - [2023-07-20 07:08:08,982] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:08:08,997] {logging_mixin.py:109} INFO - [2023-07-20 07:08:08,997] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:08:09,007] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.994 seconds
[2023-07-20 07:08:18,073] {processor.py:163} INFO - Started process (PID=532) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:18,074] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:08:18,075] {logging_mixin.py:109} INFO - [2023-07-20 07:08:18,075] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:18,735] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:18,769] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 8, 18, 754601, tzinfo=Timezone('UTC')), 'duration': 126}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:08:18,785] {logging_mixin.py:109} INFO - [2023-07-20 07:08:18,784] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:08:18,799] {logging_mixin.py:109} INFO - [2023-07-20 07:08:18,799] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:08:18,809] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.741 seconds
[2023-07-20 07:08:28,150] {processor.py:163} INFO - Started process (PID=547) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:28,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:08:28,152] {logging_mixin.py:109} INFO - [2023-07-20 07:08:28,152] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:28,810] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:28,849] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 8, 28, 830878, tzinfo=Timezone('UTC')), 'duration': 136}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:08:28,866] {logging_mixin.py:109} INFO - [2023-07-20 07:08:28,866] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:08:28,882] {logging_mixin.py:109} INFO - [2023-07-20 07:08:28,882] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:08:28,893] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.748 seconds
[2023-07-20 07:08:38,241] {processor.py:163} INFO - Started process (PID=563) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:38,244] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:08:38,245] {logging_mixin.py:109} INFO - [2023-07-20 07:08:38,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:39,120] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:39,155] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 8, 39, 139943, tzinfo=Timezone('UTC')), 'duration': 146}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:08:39,175] {logging_mixin.py:109} INFO - [2023-07-20 07:08:39,175] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:08:39,190] {logging_mixin.py:109} INFO - [2023-07-20 07:08:39,190] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:08:39,199] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.964 seconds
[2023-07-20 07:08:48,280] {processor.py:163} INFO - Started process (PID=569) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:48,281] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:08:48,282] {logging_mixin.py:109} INFO - [2023-07-20 07:08:48,282] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:49,025] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:49,059] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 8, 49, 43483, tzinfo=Timezone('UTC')), 'duration': 156}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:08:49,077] {logging_mixin.py:109} INFO - [2023-07-20 07:08:49,077] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:08:49,093] {logging_mixin.py:109} INFO - [2023-07-20 07:08:49,093] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:08:49,103] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.828 seconds
[2023-07-20 07:08:58,368] {processor.py:163} INFO - Started process (PID=584) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:58,369] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:08:58,370] {logging_mixin.py:109} INFO - [2023-07-20 07:08:58,370] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:59,020] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:08:59,052] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 8, 59, 38040, tzinfo=Timezone('UTC')), 'duration': 166}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:08:59,068] {logging_mixin.py:109} INFO - [2023-07-20 07:08:59,068] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:08:59,082] {logging_mixin.py:109} INFO - [2023-07-20 07:08:59,081] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:08:59,092] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.731 seconds
[2023-07-20 07:09:08,445] {processor.py:163} INFO - Started process (PID=600) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:08,446] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:09:08,447] {logging_mixin.py:109} INFO - [2023-07-20 07:09:08,446] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:09,090] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:09,122] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 9, 9, 108559, tzinfo=Timezone('UTC')), 'duration': 176}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:09:09,138] {logging_mixin.py:109} INFO - [2023-07-20 07:09:09,137] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:09:09,151] {logging_mixin.py:109} INFO - [2023-07-20 07:09:09,151] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:09:09,160] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.720 seconds
[2023-07-20 07:09:18,558] {processor.py:163} INFO - Started process (PID=615) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:18,562] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:09:18,563] {logging_mixin.py:109} INFO - [2023-07-20 07:09:18,562] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:19,248] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:19,278] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 9, 19, 265620, tzinfo=Timezone('UTC')), 'duration': 187}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:09:19,295] {logging_mixin.py:109} INFO - [2023-07-20 07:09:19,295] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:09:19,308] {logging_mixin.py:109} INFO - [2023-07-20 07:09:19,308] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:09:19,318] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.765 seconds
[2023-07-20 07:09:28,638] {processor.py:163} INFO - Started process (PID=627) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:28,641] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:09:28,642] {logging_mixin.py:109} INFO - [2023-07-20 07:09:28,642] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:29,392] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:29,438] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 9, 29, 420148, tzinfo=Timezone('UTC')), 'duration': 197}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:09:29,463] {logging_mixin.py:109} INFO - [2023-07-20 07:09:29,462] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:09:29,485] {logging_mixin.py:109} INFO - [2023-07-20 07:09:29,484] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:09:29,497] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.866 seconds
[2023-07-20 07:09:38,722] {processor.py:163} INFO - Started process (PID=635) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:38,724] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:09:38,724] {logging_mixin.py:109} INFO - [2023-07-20 07:09:38,724] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:39,387] {processor.py:654} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:39,421] {processor.py:584} ERROR - Error executing TaskCallbackRequest callback for file: /opt/airflow/dags/ingest_data.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
psycopg2.errors.UndefinedColumn: column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 575, in execute_callbacks
    self._execute_task_callbacks(dagbag, request)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/dag_processing/processor.py", line 607, in _execute_task_callbacks
    ti.handle_failure_with_callback(error=request.msg, test_mode=self.UNIT_TEST_MODE)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1765, in handle_failure_with_callback
    self.handle_failure(error=error, test_mode=test_mode, force_fail=force_fail, session=session)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 67, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1755, in handle_failure
    session.flush()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2540, in flush
    self._flush(objects)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2682, in _flush
    transaction.rollback(_capture_exception=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/session.py", line 2642, in _flush
    flush_context.execute()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 422, in execute
    rec.execute(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/unitofwork.py", line 589, in execute
    uow,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 245, in save_obj
    insert,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/orm/persistence.py", line 1136, in _emit_insert_statements
    statement, params
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1277, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 608, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "execution_date" of relation "task_fail" does not exist
LINE 1: INSERT INTO task_fail (task_id, dag_id, execution_date, star...
                                                ^

[SQL: INSERT INTO task_fail (task_id, dag_id, execution_date, start_date, end_date, duration) VALUES (%(task_id)s, %(dag_id)s, %(execution_date)s, %(start_date)s, %(end_date)s, %(duration)s) RETURNING task_fail.id]
[parameters: {'task_id': 'download_dataset_task', 'dag_id': 'data_ingest', 'execution_date': datetime.datetime(2023, 7, 19, 0, 0, tzinfo=Timezone('UTC')), 'start_date': datetime.datetime(2023, 7, 20, 7, 6, 12, 236463, tzinfo=Timezone('UTC')), 'end_date': datetime.datetime(2023, 7, 20, 7, 9, 39, 406232, tzinfo=Timezone('UTC')), 'duration': 207}]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2023-07-20 07:09:39,436] {logging_mixin.py:109} INFO - [2023-07-20 07:09:39,436] {dag.py:2396} INFO - Sync 1 DAGs
[2023-07-20 07:09:39,450] {logging_mixin.py:109} INFO - [2023-07-20 07:09:39,450] {dag.py:2935} INFO - Setting next_dagrun for data_ingest to None
[2023-07-20 07:09:39,459] {processor.py:171} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.742 seconds
[2023-07-20 07:09:48,828] {processor.py:163} INFO - Started process (PID=650) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:48,836] {processor.py:642} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20 07:09:48,837] {logging_mixin.py:109} INFO - [2023-07-20 07:09:48,837] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20 07:09:50,276] {logging_mixin.py:109} INFO - [2023-07-20 07:09:50,276] {process_utils.py:237} INFO - Waiting up to 5 seconds for processes to exit...
[2023-07-20T07:15:01.226+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:01.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:15:01.231+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:01.230+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:05.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:06.033+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:06.033+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:data_ingest
[2023-07-20T07:15:06.063+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:06.063+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:15:06.102+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:06.101+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:15:06.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 4.915 seconds
[2023-07-20T07:15:11.355+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:11.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:15:11.358+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:11.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:12.289+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:12.327+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:12.327+0000] {taskinstance.py:1826} ERROR - {'DAG Id': 'data_ingest', 'Task Id': 'download_dataset_task', 'Run Id': 'scheduled__2023-07-19T00:00:00+00:00', 'Hostname': '7a01217b8eac', 'External Executor Id': '32d8c6bb-5ee8-4e16-a29e-bcbf4b45343d'}
[2023-07-20T07:15:12.354+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:12.354+0000] {taskinstance.py:1350} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingest, task_id=download_dataset_task, execution_date=20230719T000000, start_date=20230720T070612, end_date=20230720T071512
[2023-07-20T07:15:12.371+0000] {processor.py:787} INFO - Executed failure callback for <TaskInstance: data_ingest.download_dataset_task scheduled__2023-07-19T00:00:00+00:00 [up_for_retry]> in state up_for_retry
[2023-07-20T07:15:12.378+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:12.378+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:15:12.409+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:12.409+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:15:12.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.095 seconds
[2023-07-20T07:15:42.536+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:42.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:15:42.539+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:42.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:43.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:15:43.389+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:43.389+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:15:43.424+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:15:43.423+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:15:43.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.923 seconds
[2023-07-20T07:16:13.635+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:16:13.636+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:16:13.637+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:16:13.637+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:16:14.449+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:16:14.486+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:16:14.486+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:16:14.523+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:16:14.523+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:16:14.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.922 seconds
[2023-07-20T07:16:44.735+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:16:44.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:16:44.740+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:16:44.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:16:45.524+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:16:45.560+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:16:45.560+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:16:45.596+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:16:45.596+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:16:45.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.892 seconds
[2023-07-20T07:17:15.808+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:17:15.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:17:15.814+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:17:15.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:17:16.690+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:17:16.731+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:17:16.731+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:17:16.771+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:17:16.771+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:17:16.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.996 seconds
[2023-07-20T07:17:46.974+0000] {processor.py:157} INFO - Started process (PID=113) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:17:46.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:17:46.977+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:17:46.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:17:47.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:17:47.837+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:17:47.837+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:17:47.874+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:17:47.873+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:17:47.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.931 seconds
[2023-07-20T07:18:18.185+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:18:18.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:18:18.196+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:18:18.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:18:20.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:18:20.479+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:18:20.478+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:18:20.547+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:18:20.547+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:18:20.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 2.429 seconds
[2023-07-20T07:18:50.806+0000] {processor.py:157} INFO - Started process (PID=145) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:18:50.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:18:50.811+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:18:50.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:18:51.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:18:51.852+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:18:51.852+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:18:51.893+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:18:51.893+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:18:51.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.125 seconds
[2023-07-20T07:19:21.969+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:19:21.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:19:21.971+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:19:21.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:19:22.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:19:22.868+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:19:22.868+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:19:22.910+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:19:22.909+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:19:22.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.978 seconds
[2023-07-20T07:19:53.128+0000] {processor.py:157} INFO - Started process (PID=169) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:19:53.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:19:53.131+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:19:53.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:19:53.978+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:19:54.019+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:19:54.019+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:19:54.058+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:19:54.058+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:19:54.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.967 seconds
[2023-07-20T07:20:24.305+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:20:24.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:20:24.309+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:20:24.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:20:25.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:20:25.287+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:20:25.287+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:20:25.329+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:20:25.329+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:20:25.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.059 seconds
[2023-07-20T07:25:11.259+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:25:11.291+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:25:11.292+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:25:11.292+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:25:14.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:25:14.963+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:25:14.963+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:25:15.000+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:25:15.000+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:25:15.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 3.780 seconds
[2023-07-20T07:25:45.215+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:25:45.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:25:45.217+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:25:45.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:25:46.027+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:25:46.066+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:25:46.066+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:25:46.105+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:25:46.105+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:25:46.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.947 seconds
[2023-07-20T07:26:16.356+0000] {processor.py:157} INFO - Started process (PID=73) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:26:16.358+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:26:16.360+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:26:16.359+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:26:17.168+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:26:17.204+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:26:17.203+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:26:17.240+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:26:17.239+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:26:17.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.922 seconds
[2023-07-20T07:26:47.459+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:26:47.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:26:47.463+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:26:47.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:26:48.320+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:26:48.357+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:26:48.357+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:26:48.393+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:26:48.393+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:26:48.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.970 seconds
[2023-07-20T07:27:18.619+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:27:18.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:27:18.621+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:27:18.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:27:19.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:27:19.479+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:27:19.478+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:27:19.517+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:27:19.517+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:27:19.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.933 seconds
[2023-07-20T07:27:49.734+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:27:49.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:27:49.739+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:27:49.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:27:50.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:27:50.595+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:27:50.594+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:27:50.633+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:27:50.633+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:27:50.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.941 seconds
[2023-07-20T07:28:20.850+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:28:20.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:28:20.855+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:28:20.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:28:21.682+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:28:21.720+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:28:21.720+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:28:21.759+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:28:21.759+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:28:21.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.940 seconds
[2023-07-20T07:28:51.961+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:28:51.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:28:51.963+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:28:51.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:28:52.810+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:28:52.856+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:28:52.856+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:28:52.890+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:28:52.890+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:28:52.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.965 seconds
[2023-07-20T07:29:23.107+0000] {processor.py:157} INFO - Started process (PID=148) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:29:23.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:29:23.112+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:29:23.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:29:23.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:29:24.028+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:29:24.028+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:29:24.066+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:29:24.066+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:29:24.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.995 seconds
[2023-07-20T07:29:54.272+0000] {processor.py:157} INFO - Started process (PID=160) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:29:54.273+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:29:54.275+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:29:54.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:29:55.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:29:55.125+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:29:55.124+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:29:55.182+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:29:55.181+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:29:55.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.955 seconds
[2023-07-20T07:30:25.440+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:30:25.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:30:25.443+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:30:25.443+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:30:26.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:30:26.289+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:30:26.289+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:30:26.326+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:30:26.326+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:30:26.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.915 seconds
[2023-07-20T07:30:56.539+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:30:56.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:30:56.544+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:30:56.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:30:57.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:30:57.377+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:30:57.377+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:30:57.412+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:30:57.411+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:30:57.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.904 seconds
[2023-07-20T07:31:18.586+0000] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:31:18.587+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:31:18.589+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:31:18.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:31:19.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:31:19.475+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:31:19.475+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:31:19.513+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:31:19.513+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:31:19.544+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.964 seconds
[2023-07-20T07:31:49.738+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:31:49.742+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:31:49.743+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:31:49.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:31:50.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:31:50.633+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:31:50.632+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:31:50.669+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:31:50.668+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:31:50.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.963 seconds
[2023-07-20T07:32:20.888+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:32:20.890+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:32:20.891+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:32:20.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:32:21.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:32:21.851+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:32:21.851+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:32:21.887+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:32:21.887+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:32:21.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.032 seconds
[2023-07-20T07:32:52.055+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:32:52.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:32:52.060+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:32:52.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:32:52.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:32:52.986+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:32:52.985+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:32:53.028+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:32:53.028+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:32:53.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.014 seconds
[2023-07-20T07:33:23.249+0000] {processor.py:157} INFO - Started process (PID=246) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:33:23.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:33:23.251+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:33:23.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:33:24.109+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:33:24.148+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:33:24.148+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:33:24.192+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:33:24.191+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:33:24.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.981 seconds
[2023-07-20T07:33:54.432+0000] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:33:54.435+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:33:54.437+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:33:54.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:33:55.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:33:55.779+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:33:55.778+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:33:55.833+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:33:55.833+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:33:55.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.451 seconds
[2023-07-20T07:34:26.075+0000] {processor.py:157} INFO - Started process (PID=271) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:34:26.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:34:26.078+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:34:26.077+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:34:26.896+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:34:26.934+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:34:26.933+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:34:26.968+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:34:26.968+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:34:26.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.927 seconds
[2023-07-20T07:34:57.168+0000] {processor.py:157} INFO - Started process (PID=283) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:34:57.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:34:57.172+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:34:57.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:34:58.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:34:58.045+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:34:58.044+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:34:58.082+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:34:58.082+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:34:58.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.949 seconds
[2023-07-20T07:35:28.277+0000] {processor.py:157} INFO - Started process (PID=295) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:35:28.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:35:28.281+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:35:28.280+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:35:29.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:35:29.125+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:35:29.124+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:35:29.163+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:35:29.162+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:35:29.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.917 seconds
[2023-07-20T07:35:59.359+0000] {processor.py:157} INFO - Started process (PID=307) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:35:59.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:35:59.364+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:35:59.363+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:36:00.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:36:00.310+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:36:00.309+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:36:00.346+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:36:00.346+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:36:00.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.021 seconds
[2023-07-20T07:36:30.526+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:36:30.527+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:36:30.528+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:36:30.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:36:31.330+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:36:31.376+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:36:31.376+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:36:31.420+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:36:31.420+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:36:31.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.932 seconds
[2023-07-20T07:37:01.645+0000] {processor.py:157} INFO - Started process (PID=330) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:37:01.647+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:37:01.648+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:37:01.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:37:02.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:37:02.571+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:37:02.571+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:37:02.607+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:37:02.607+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:37:02.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.998 seconds
[2023-07-20T07:37:32.813+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:37:32.814+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:37:32.816+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:37:32.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:37:33.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:37:33.691+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:37:33.691+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:37:33.729+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:37:33.729+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:37:33.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.949 seconds
[2023-07-20T07:38:03.948+0000] {processor.py:157} INFO - Started process (PID=362) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:38:03.949+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:38:03.951+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:38:03.950+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:38:04.790+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:38:04.829+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:38:04.828+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:38:04.869+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:38:04.869+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:38:04.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.961 seconds
[2023-07-20T07:38:35.089+0000] {processor.py:157} INFO - Started process (PID=374) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:38:35.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:38:35.093+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:38:35.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:38:35.925+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:38:35.964+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:38:35.964+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:38:36.000+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:38:36.000+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:38:36.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.953 seconds
[2023-07-20T07:39:06.234+0000] {processor.py:157} INFO - Started process (PID=386) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:39:06.237+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:39:06.239+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:39:06.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:39:07.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:39:07.208+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:39:07.208+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:39:07.246+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:39:07.246+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:39:07.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.047 seconds
[2023-07-20T07:39:37.407+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:39:37.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:39:37.410+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:39:37.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:39:38.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:39:38.266+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:39:38.265+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:39:38.318+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:39:38.317+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:39:38.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.947 seconds
[2023-07-20T07:40:08.543+0000] {processor.py:157} INFO - Started process (PID=411) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:08.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:40:08.547+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:08.547+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:09.378+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:09.416+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:09.416+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:40:09.456+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:09.456+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:40:09.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.951 seconds
[2023-07-20T07:40:10.533+0000] {processor.py:157} INFO - Started process (PID=416) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:10.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:40:10.536+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:10.535+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:11.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:11.464+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:11.464+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:40:11.502+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:11.502+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:40:11.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.006 seconds
[2023-07-20T07:40:41.735+0000] {processor.py:157} INFO - Started process (PID=428) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:41.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:40:41.738+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:41.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:42.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:40:42.580+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:42.580+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:40:42.616+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:40:42.616+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:40:42.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.913 seconds
[2023-07-20T07:41:12.836+0000] {processor.py:157} INFO - Started process (PID=440) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:41:12.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:41:12.840+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:41:12.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:41:13.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:41:13.683+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:41:13.682+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:41:13.717+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:41:13.717+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:41:13.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.922 seconds
[2023-07-20T07:41:43.952+0000] {processor.py:157} INFO - Started process (PID=452) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:41:43.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:41:43.955+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:41:43.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:41:44.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:41:44.850+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:41:44.850+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:41:44.885+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:41:44.885+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:41:44.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.966 seconds
[2023-07-20T07:42:15.102+0000] {processor.py:157} INFO - Started process (PID=464) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:42:15.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:42:15.105+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:42:15.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:42:15.922+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:42:15.957+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:42:15.957+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:42:15.993+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:42:15.992+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:42:16.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.927 seconds
[2023-07-20T07:42:38.175+0000] {processor.py:157} INFO - Started process (PID=476) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:42:38.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:42:38.178+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:42:38.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:42:38.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:42:39.022+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:42:39.021+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:42:39.061+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:42:39.060+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:42:39.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.927 seconds
[2023-07-20T07:43:09.280+0000] {processor.py:157} INFO - Started process (PID=488) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:43:09.282+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:43:09.284+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:43:09.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:43:10.143+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:43:10.181+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:43:10.181+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:43:10.219+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:43:10.218+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:43:10.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.976 seconds
[2023-07-20T07:43:40.441+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:43:40.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:43:40.445+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:43:40.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:43:41.292+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:43:41.332+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:43:41.332+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:43:41.366+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:43:41.366+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:43:41.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.959 seconds
[2023-07-20T07:44:03.546+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:03.548+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:44:03.549+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:03.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:04.375+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:04.424+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:04.424+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:44:04.467+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:04.467+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:44:04.510+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.970 seconds
[2023-07-20T07:44:34.709+0000] {processor.py:157} INFO - Started process (PID=523) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:34.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:44:34.713+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:34.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:35.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:35.566+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:35.566+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:44:35.602+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:35.602+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:44:35.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.924 seconds
[2023-07-20T07:44:57.779+0000] {processor.py:157} INFO - Started process (PID=528) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:57.780+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:44:57.781+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:57.781+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:58.611+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:44:58.650+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:58.650+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:44:58.689+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:44:58.689+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:44:58.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.945 seconds
[2023-07-20T07:45:28.936+0000] {processor.py:157} INFO - Started process (PID=539) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:45:28.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:45:28.939+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:45:28.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:45:29.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:45:29.807+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:45:29.807+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:45:29.845+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:45:29.845+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:45:29.879+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.949 seconds
[2023-07-20T07:46:00.073+0000] {processor.py:157} INFO - Started process (PID=551) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:00.075+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:46:00.076+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:00.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:00.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:00.930+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:00.930+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:46:00.966+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:00.965+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:46:00.993+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.925 seconds
[2023-07-20T07:46:22.145+0000] {processor.py:157} INFO - Started process (PID=563) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:22.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:46:22.149+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:22.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:23.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:23.219+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:23.219+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:46:23.253+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:23.253+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:46:23.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.147 seconds
[2023-07-20T07:46:53.349+0000] {processor.py:157} INFO - Started process (PID=575) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:53.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:46:53.353+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:53.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:54.297+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:46:54.344+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:54.344+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:46:54.384+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:46:54.383+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:46:54.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.071 seconds
[2023-07-20T07:47:24.516+0000] {processor.py:157} INFO - Started process (PID=587) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:47:24.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:47:24.519+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:47:24.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:47:25.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:47:25.399+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:47:25.399+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:47:25.445+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:47:25.444+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:47:25.482+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.972 seconds
[2023-07-20T07:47:55.672+0000] {processor.py:157} INFO - Started process (PID=598) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:47:55.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:47:55.675+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:47:55.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:47:56.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:47:56.492+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:47:56.491+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:47:56.527+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:47:56.526+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:47:56.551+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.886 seconds
[2023-07-20T07:48:26.746+0000] {processor.py:157} INFO - Started process (PID=610) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:48:26.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:48:26.751+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:48:26.750+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:48:27.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:48:27.598+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:48:27.597+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:48:27.633+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:48:27.633+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:48:27.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.920 seconds
[2023-07-20T07:48:57.853+0000] {processor.py:157} INFO - Started process (PID=623) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:48:57.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:48:57.856+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:48:57.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:48:58.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:48:58.693+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:48:58.692+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:48:58.728+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:48:58.728+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:48:58.755+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.908 seconds
[2023-07-20T07:49:28.947+0000] {processor.py:157} INFO - Started process (PID=635) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:49:28.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:49:28.951+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:49:28.951+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:49:29.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:49:29.807+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:49:29.806+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:49:29.842+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:49:29.841+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:49:29.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.926 seconds
[2023-07-20T07:50:00.059+0000] {processor.py:157} INFO - Started process (PID=647) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:50:00.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:50:00.062+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:50:00.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:50:00.862+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:50:00.898+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:50:00.898+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:50:00.932+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:50:00.932+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:50:00.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.905 seconds
[2023-07-20T07:50:31.185+0000] {processor.py:157} INFO - Started process (PID=659) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:50:31.187+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:50:31.188+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:50:31.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:50:32.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:50:32.055+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:50:32.055+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:50:32.092+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:50:32.092+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:50:32.117+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.939 seconds
[2023-07-20T07:51:02.311+0000] {processor.py:157} INFO - Started process (PID=671) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:51:02.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:51:02.314+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:51:02.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:51:03.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:51:03.160+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:51:03.160+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:51:03.196+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:51:03.196+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:51:03.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.918 seconds
[2023-07-20T07:51:33.417+0000] {processor.py:157} INFO - Started process (PID=683) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:51:33.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:51:33.421+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:51:33.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:51:34.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:51:34.265+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:51:34.265+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:51:34.300+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:51:34.299+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:51:34.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.916 seconds
[2023-07-20T07:52:04.512+0000] {processor.py:157} INFO - Started process (PID=695) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:52:04.514+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:52:04.515+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:52:04.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:52:05.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:52:05.375+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:52:05.374+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:52:05.410+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:52:05.409+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:52:05.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.938 seconds
[2023-07-20T07:52:35.645+0000] {processor.py:157} INFO - Started process (PID=715) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:52:35.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:52:35.647+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:52:35.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:52:36.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:52:36.483+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:52:36.483+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:52:36.519+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:52:36.518+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:52:36.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.905 seconds
[2023-07-20T07:53:06.730+0000] {processor.py:157} INFO - Started process (PID=727) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:53:06.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:53:06.736+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:06.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:53:07.546+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:53:07.583+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:07.582+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:53:07.618+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:07.617+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:53:07.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.919 seconds
[2023-07-20T07:53:37.835+0000] {processor.py:157} INFO - Started process (PID=739) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:53:37.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:53:37.839+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:37.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:53:38.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:53:38.819+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:38.819+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:53:38.839+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:38.838+0000] {dag.py:2763} INFO - Creating ORM DAG for data_ingest
[2023-07-20T07:53:38.855+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:53:38.854+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00, run_after=2023-07-19T00:00:00+00:00
[2023-07-20T07:53:38.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.053 seconds
[2023-07-20T07:56:10.381+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:56:10.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:56:10.394+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:56:10.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:56:13.028+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:56:13.401+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:56:13.400+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:56:13.450+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:56:13.450+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00, run_after=2023-07-19T00:00:00+00:00
[2023-07-20T07:56:13.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 3.152 seconds
[2023-07-20T07:56:43.661+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:56:43.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:56:43.665+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:56:43.665+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:56:44.444+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:56:44.481+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:56:44.481+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:56:44.515+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:56:44.515+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to 2023-07-19T00:00:00+00:00, run_after=2023-07-19T00:00:00+00:00
[2023-07-20T07:56:44.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.884 seconds
[2023-07-20T07:57:14.722+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:57:14.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:57:14.725+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:57:14.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:57:15.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:57:15.580+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:57:15.580+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:57:15.614+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:57:15.614+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:57:15.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.926 seconds
[2023-07-20T07:57:45.831+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:57:45.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:57:45.836+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:57:45.836+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:57:46.655+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:57:46.696+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:57:46.695+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:57:46.735+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:57:46.734+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:57:46.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.946 seconds
[2023-07-20T07:58:16.965+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:58:16.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:58:16.967+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:58:16.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:58:17.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:58:17.871+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:58:17.870+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:58:17.913+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:58:17.913+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:58:17.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.984 seconds
[2023-07-20T07:58:48.129+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:58:48.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:58:48.131+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:58:48.131+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:58:48.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:58:49.056+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:58:49.055+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:58:49.125+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:58:49.124+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:58:49.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.032 seconds
[2023-07-20T07:59:19.297+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:59:19.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:59:19.305+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:59:19.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:59:20.154+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:59:20.195+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:59:20.194+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:59:20.229+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:59:20.229+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:59:20.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.965 seconds
[2023-07-20T07:59:50.452+0000] {processor.py:157} INFO - Started process (PID=138) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T07:59:50.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T07:59:50.456+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:59:50.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:59:51.304+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T07:59:51.342+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:59:51.342+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T07:59:51.379+0000] {logging_mixin.py:150} INFO - [2023-07-20T07:59:51.378+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T07:59:51.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.960 seconds
[2023-07-20T08:00:21.602+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:00:21.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:00:21.606+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:00:21.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:00:22.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:00:22.511+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:00:22.511+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:00:22.553+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:00:22.553+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:00:22.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.992 seconds
[2023-07-20T08:00:52.764+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:00:52.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:00:52.766+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:00:52.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:00:53.560+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:00:53.597+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:00:53.596+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:00:53.633+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:00:53.633+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:00:53.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.901 seconds
[2023-07-20T08:01:09.776+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:01:09.780+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:01:09.781+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:01:09.781+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:01:10.671+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:01:10.717+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:01:10.717+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:01:10.765+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:01:10.765+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:01:10.804+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.034 seconds
[2023-07-20T08:01:40.988+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:01:40.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:01:40.991+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:01:40.990+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:01:41.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:01:41.907+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:01:41.906+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:01:41.962+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:01:41.962+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:01:42.001+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.019 seconds
[2023-07-20T08:02:12.165+0000] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:02:12.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:02:12.169+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:02:12.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:02:12.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:02:13.011+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:02:13.011+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:02:13.047+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:02:13.047+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:02:13.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.915 seconds
[2023-07-20T08:02:43.268+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:02:43.271+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:02:43.272+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:02:43.272+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:02:44.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:02:44.161+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:02:44.161+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:02:44.200+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:02:44.199+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:02:44.231+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.970 seconds
[2023-07-20T08:03:14.413+0000] {processor.py:157} INFO - Started process (PID=221) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:03:14.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:03:14.415+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:03:14.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:03:15.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:03:15.274+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:03:15.274+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:03:15.310+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:03:15.310+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:03:15.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.929 seconds
[2023-07-20T08:03:45.532+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:03:45.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:03:45.537+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:03:45.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:03:46.359+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:03:46.394+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:03:46.394+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:03:46.429+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:03:46.429+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:03:46.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.926 seconds
[2023-07-20T08:06:01.228+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:06:01.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:06:01.248+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:06:01.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:06:04.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:06:04.833+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:06:04.833+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:06:04.888+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:06:04.887+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:06:04.931+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 3.709 seconds
[2023-07-20T08:06:35.126+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:06:35.127+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:06:35.128+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:06:35.128+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:06:35.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:06:36.040+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:06:36.039+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:06:36.077+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:06:36.076+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:06:36.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.986 seconds
[2023-07-20T08:07:06.310+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:07:06.314+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:07:06.315+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:07:06.315+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:07:07.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:07:07.263+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:07:07.263+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:07:07.299+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:07:07.298+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:07:07.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.025 seconds
[2023-07-20T08:07:37.480+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:07:37.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:07:37.484+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:07:37.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:07:38.317+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:07:38.356+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:07:38.356+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:07:38.398+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:07:38.398+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:07:38.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.954 seconds
[2023-07-20T08:08:08.616+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:08:08.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:08:08.621+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:08:08.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:08:09.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:08:09.486+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:08:09.486+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:08:09.525+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:08:09.525+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:08:09.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.945 seconds
[2023-07-20T08:08:39.744+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:08:39.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:08:39.746+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:08:39.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:08:40.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:08:40.595+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:08:40.595+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:08:40.630+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:08:40.630+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:08:40.656+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.918 seconds
[2023-07-20T08:09:10.847+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:10.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:09:10.850+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:10.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:11.690+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:11.728+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:11.727+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:09:11.764+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:11.763+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:09:11.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.951 seconds
[2023-07-20T08:09:41.977+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:41.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:09:41.980+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:41.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:42.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:42.862+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:42.862+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:09:42.898+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:42.898+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:09:42.925+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.954 seconds
[2023-07-20T08:09:55.024+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:55.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:09:55.029+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:55.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:55.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:09:56.018+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:56.017+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:09:56.055+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:09:56.054+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:09:56.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 1.071 seconds
[2023-07-20T08:10:03.122+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:10:03.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:10:03.125+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:10:03.124+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:10:03.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:10:03.983+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:10:03.983+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:10:04.021+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:10:04.020+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:10:04.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.934 seconds
[2023-07-20T08:10:34.233+0000] {processor.py:157} INFO - Started process (PID=161) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:10:34.236+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:10:34.237+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:10:34.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:10:35.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:10:35.107+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:10:35.106+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:10:35.147+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:10:35.147+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:10:35.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.950 seconds
[2023-07-20T08:11:05.397+0000] {processor.py:157} INFO - Started process (PID=173) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:11:05.398+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:11:05.399+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:11:05.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:11:06.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:11:06.239+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:11:06.238+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:11:06.275+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:11:06.274+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:11:06.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.910 seconds
[2023-07-20T08:11:36.495+0000] {processor.py:157} INFO - Started process (PID=185) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:11:36.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:11:36.500+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:11:36.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:11:37.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:11:37.419+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:11:37.419+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:11:37.460+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:11:37.460+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:11:37.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.998 seconds
[2023-07-20T08:12:07.667+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:12:07.669+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:12:07.670+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:12:07.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:12:08.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:12:08.517+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:12:08.517+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:12:08.553+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:12:08.553+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:12:08.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.923 seconds
[2023-07-20T08:12:19.672+0000] {processor.py:157} INFO - Started process (PID=203) to work on /opt/airflow/dags/ingest_data.py
[2023-07-20T08:12:19.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/ingest_data.py for tasks to queue
[2023-07-20T08:12:19.674+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:12:19.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:12:20.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['data_ingest']) retrieved from /opt/airflow/dags/ingest_data.py
[2023-07-20T08:12:20.558+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:12:20.558+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-07-20T08:12:20.596+0000] {logging_mixin.py:150} INFO - [2023-07-20T08:12:20.596+0000] {dag.py:3508} INFO - Setting next_dagrun for data_ingest to None, run_after=None
[2023-07-20T08:12:20.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/ingest_data.py took 0.960 seconds
